model_name_or_path: ./models/Llama3-8B-Chinese-Chat
template: llama3
infer_backend: vllm
vllm_enforce_eager: true
